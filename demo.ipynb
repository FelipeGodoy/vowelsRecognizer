{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.constants as const\n",
    "import scipy\n",
    "import IPython.display\n",
    "from scipy.io import wavfile\n",
    "from IPython.core.display import HTML\n",
    "from __future__ import division\n",
    "from tensorflow.python.platform import gfile\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TEST = \"./dataset/test\"\n",
    "PATH_TRAINING = \"./dataset/train\"\n",
    "n_mfcc = 20\n",
    "mfcc_start = 0\n",
    "mfcc_end = 20\n",
    "mfcc_stored = mfcc_end - mfcc_start\n",
    "n_samples = 6\n",
    "\n",
    "def load_vowel(folder, size=4):\n",
    "    wav_files = os.listdir(folder)[0:size]\n",
    "    dataset = np.ndarray(shape=(len(wav_files) * 8, mfcc_stored, n_samples), dtype=np.float32)\n",
    "    num_files = 0\n",
    "    for wav_file in wav_files:\n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.125, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.25, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.375, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.5, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.625, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.75, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.875, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('Mean:', np.mean(dataset))\n",
    "    print('Standard deviation:', np.std(dataset))\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: 0.002263088\n",
      "Standard deviation: 0.28876427\n",
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: -8.529096e-05\n",
      "Standard deviation: 0.3437524\n",
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: 0.002041483\n",
      "Standard deviation: 0.32866862\n",
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: 0.0044583115\n",
      "Standard deviation: 0.36659002\n",
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: -0.007859334\n",
      "Standard deviation: 0.42994225\n",
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: -0.0023001232\n",
      "Standard deviation: 0.37406784\n",
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: -0.048689034\n",
      "Standard deviation: 0.4482279\n",
      "Datasets Shape: (224, 20, 6) (224,)\n"
     ]
    }
   ],
   "source": [
    "def load_datasets(folder, size):\n",
    "    vowels = os.listdir(folder)\n",
    "    label = 0\n",
    "    vowels_amount = len(vowels)\n",
    "    datasets = np.ndarray(shape=(vowels_amount * size * 8, mfcc_stored, n_samples), dtype=np.float32)\n",
    "    labels = np.ndarray(shape=(vowels_amount * size * 8), dtype=np.int)\n",
    "    ind_start, ind_end = 0, size *8\n",
    "    for vowel in vowels:\n",
    "        vowel_folder = os.path.join(folder, vowel)\n",
    "        vowel_dataset = load_vowel(vowel_folder, size)\n",
    "        datasets[ind_start:ind_end,:,:] = vowel_dataset\n",
    "        labels[ind_start:ind_end] = label\n",
    "        ind_start += size * 8\n",
    "        ind_end += size * 8\n",
    "        label += 1\n",
    "    print(\"Datasets Shape:\", datasets.shape, labels.shape)\n",
    "    return datasets, labels\n",
    "\n",
    "datasets, labels = load_datasets(PATH_TRAINING, 4)\n",
    "\n",
    "#Randomize dataset\n",
    "np.random.seed(133)\n",
    "permutation = np.random.permutation(labels.shape[0])\n",
    "datasets = datasets[permutation,:,:]\n",
    "labels = labels[permutation]\n",
    "\n",
    "#save dataset\n",
    "pickle_file = os.path.join(\"./\", 'vowels.pickle')\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': datasets,\n",
    "    'train_labels': labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x2c412b0ce48>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mfccs = datasets[0,:,:]\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title = \"MFCC\"\n",
    "librosa.display.specshow(mfccs, x_axis='time')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (224, 120) (224, 7)\n"
     ]
    }
   ],
   "source": [
    "num_labels = 7\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, mfcc_stored * n_samples)).astype(np.float32)\n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(datasets, labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    # Load the training, validation and test data into constants that are\n",
    "    # attached to the graph.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,shape=(num_labels * 4 * 8, mfcc_stored * n_samples))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(num_labels * 4 * 8, num_labels))\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal([mfcc_stored * n_samples, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    tf_inference_input = tf.placeholder(tf.float32,shape=(1, mfcc_stored * n_samples), name=\"input\")\n",
    "    inf_logits = tf.matmul(tf_inference_input, weights) + biases\n",
    "    inf_prediction = tf.nn.softmax(inf_logits, name=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 6.245766\n",
      "Training accuracy: 21.0%\n",
      "Loss at step 100: 1.791763\n",
      "Training accuracy: 40.2%\n",
      "Loss at step 200: 1.405735\n",
      "Training accuracy: 56.7%\n",
      "Loss at step 300: 1.126850\n",
      "Training accuracy: 70.1%\n",
      "Loss at step 400: 0.919928\n",
      "Training accuracy: 88.8%\n",
      "Loss at step 500: 0.765569\n",
      "Training accuracy: 97.3%\n",
      "Loss at step 600: 0.649149\n",
      "Training accuracy: 98.2%\n",
      "Loss at step 700: 0.559868\n",
      "Training accuracy: 98.7%\n",
      "Loss at step 800: 0.490101\n",
      "Training accuracy: 99.1%\n",
      "Loss at step 900: 0.434560\n",
      "Training accuracy: 99.1%\n",
      "Loss at step 1000: 0.389569\n",
      "Training accuracy: 99.1%\n",
      "Loss at step 1100: 0.352546\n",
      "Training accuracy: 99.6%\n",
      "Loss at step 1200: 0.321645\n",
      "Training accuracy: 99.6%\n",
      "Loss at step 1300: 0.295526\n",
      "Training accuracy: 99.6%\n",
      "Loss at step 1400: 0.273198\n",
      "Training accuracy: 99.6%\n",
      "Loss at step 1500: 0.253920\n",
      "Training accuracy: 99.6%\n",
      "Loss at step 1600: 0.237123\n",
      "Training accuracy: 99.6%\n",
      "Loss at step 1700: 0.222370\n",
      "Training accuracy: 99.6%\n",
      "Loss at step 1800: 0.209318\n",
      "Training accuracy: 99.6%\n",
      "Loss at step 1900: 0.197695\n",
      "Training accuracy: 99.6%\n",
      "Loss at step 2000: 0.187282\n",
      "Training accuracy: 99.6%\n",
      "Saved checkpoint\n"
     ]
    }
   ],
   "source": [
    "num_steps = 2001\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    feed_dict = {tf_train_dataset : train_dataset, tf_train_labels : train_labels}\n",
    "    for step in range(num_steps):\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 100 == 0):\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Training accuracy: %.1f%%' % accuracy(predictions, train_labels))\n",
    "    saver = tf.train.Saver()\n",
    "    last_checkpoint = './model.cptk'\n",
    "    saver.save(session, last_checkpoint)\n",
    "    tf.train.write_graph(session.graph_def, \"./\", 'raw_graph_def.pb', as_text=False)\n",
    "    print(\"Saved checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.cptk\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "Converted 2 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "freeze_graph.freeze_graph(input_graph = './raw_graph_def.pb',\n",
    "              input_binary = True,\n",
    "              input_checkpoint = last_checkpoint,\n",
    "              output_node_names = \"prediction\",\n",
    "              output_graph = './model.bytes' ,\n",
    "              clear_devices = True, initializer_nodes = \"\",input_saver = \"\",\n",
    "              restore_op_name = \"save/restore_all\", filename_tensor_name = \"save/Const:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
