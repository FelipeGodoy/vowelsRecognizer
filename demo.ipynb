{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.constants as const\n",
    "import scipy\n",
    "import IPython.display\n",
    "from scipy.io import wavfile\n",
    "from IPython.core.display import HTML\n",
    "from __future__ import division\n",
    "from tensorflow.python.platform import gfile\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TEST = \"./dataset/test\"\n",
    "PATH_TRAINING = \"./dataset/train\"\n",
    "n_mfcc = 20\n",
    "mfcc_start = 0\n",
    "mfcc_end = 20\n",
    "mfcc_stored = mfcc_end - mfcc_start\n",
    "n_samples = 6\n",
    "\n",
    "def load_vowel(folder, size=4):\n",
    "    wav_files = os.listdir(folder)[0:size]\n",
    "    dataset = np.ndarray(shape=(len(wav_files) * 8, mfcc_stored, n_samples), dtype=np.float32)\n",
    "    num_files = 0\n",
    "    for wav_file in wav_files:\n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.125, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.25, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.375, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.5, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.625, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.75, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.875, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('Mean:', np.mean(dataset))\n",
    "    print('Standard deviation:', np.std(dataset))\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: 0.002263088\n",
      "Standard deviation: 0.28876427\n",
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: -8.529096e-05\n",
      "Standard deviation: 0.3437524\n",
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: 0.002041483\n",
      "Standard deviation: 0.32866862\n",
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: 0.0044583115\n",
      "Standard deviation: 0.36659002\n",
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: -0.007859334\n",
      "Standard deviation: 0.42994225\n",
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: -0.0023001232\n",
      "Standard deviation: 0.37406784\n",
      "Full dataset tensor: (32, 20, 6)\n",
      "Mean: -0.048689034\n",
      "Standard deviation: 0.4482279\n",
      "Datasets Shape: (224, 20, 6) (224,)\n"
     ]
    }
   ],
   "source": [
    "def load_datasets(folder, size):\n",
    "    vowels = os.listdir(folder)\n",
    "    label = 0\n",
    "    vowels_amount = len(vowels)\n",
    "    datasets = np.ndarray(shape=(vowels_amount * size * 8, mfcc_stored, n_samples), dtype=np.float32)\n",
    "    labels = np.ndarray(shape=(vowels_amount * size * 8), dtype=np.int)\n",
    "    ind_start, ind_end = 0, size *8\n",
    "    for vowel in vowels:\n",
    "        vowel_folder = os.path.join(folder, vowel)\n",
    "        vowel_dataset = load_vowel(vowel_folder, size)\n",
    "        datasets[ind_start:ind_end,:,:] = vowel_dataset\n",
    "        labels[ind_start:ind_end] = label\n",
    "        ind_start += size * 8\n",
    "        ind_end += size * 8\n",
    "        label += 1\n",
    "    print(\"Datasets Shape:\", datasets.shape, labels.shape)\n",
    "    return datasets, labels\n",
    "\n",
    "datasets, labels = load_datasets(PATH_TRAINING, 4)\n",
    "\n",
    "#Randomize dataset\n",
    "np.random.seed(133)\n",
    "permutation = np.random.permutation(labels.shape[0])\n",
    "datasets = datasets[permutation,:,:]\n",
    "labels = labels[permutation]\n",
    "\n",
    "#save dataset\n",
    "pickle_file = os.path.join(\"./\", 'vowels.pickle')\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': datasets,\n",
    "    'train_labels': labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1990adc35f8>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwYAAAFACAYAAAAGWGuMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGyRJREFUeJzt3XuMpeddH/Dvb3bXu+v1JWuvL0ucxAl1cAJJnWJSIOISEgsk1CSoFEKhdSWiNqWUShUSllKpLVIlC6pWrYpU3FBk+keB0kLcSjRxTEKL0kAcAjFxBI5N4pjdeLPr29re+zz9Y4/jJdn1zJx5Zp6d93w+0tGcd8573vmOnj1nz2+eW7XWAgAALLal0QEAAIDxFAYAAIDCAAAAUBgAAABRGAAAAFEYAAAAURgAAABRGAAAAFEYAAAASbav5eSqmsw2yTdfdt3oCN3suemK0RH6OnZsdIJ+praz+JR+nz2Xjk7Q14kToxNwISdOjU7AhVSNTtDPlH6XJJ986MDh1to1o3Os5Hu/983tyJGn1/y8T37yzz7YWvu+DYi0LmsqDOZ+ykXol9/0Y6MjdPMtH7xtdISulj79J6Mj9HNyYh8IzpwZnaCb5W++ZXSErpb+/POjI3AhD39xdIJ+lqb14TOXTOMzTZJkx47RCbpauu2ff2F0htU4cuTp/P4f/OKan7d921v3bUCcdZvQKwIAADZRS7K8PDpFNwoDAACYS1MYAAAAURgAAMDCa5nUwhwKAwAAmIuhRAAAQKIwAACAhWdVIgAAwFAiAABgsXsMbr7suvzKX/vRjcqyqR4/vnN0hG6WHn54dIS+nnhqdIJ+XnbF6AR9nTg5OkE3S1/YEptqLqZDR0Yn6Ov6q0cn6OeSae2uO6l/a4cm9H/nltJSbUELAwAA4ByL2mMAAADMtCTL9jEAAIAFZ/IxAACwyJOPAQCAc5h8DAAAi25aQ4mWRgcAAADG02MAAADzsCoRAAAwtaFECgMAAJjXohYGz53elo8dvnKjsmyqA8dGJ+jn+//8L0ZH6Kp902tHR+imXXHF6AhdLX3qgdER+nno0dEJ+rpkQn/nOXl6dIK+rprG/5tJkmPHRyfo69qrRyfo57I9oxMsppbUohYGAADAC1rSzDEAAAD0GAAAwIKz8zEAAHB2VSJDiQAAYLHpMQAAAJIoDAAAAKsSAQAAhhIBAABJTD4GAADa4vYYVLXs3jaNquiKHTU6Qj8nT49O0FX93z8cHaGbuvV1oyN01W66cXSEburBh0ZH6Ov4qdEJ+tmza3QCLuTYidEJ+jr05OgE/Vy7d3SCxWQoEQAAkGRSQ4mWRgcAAADG02MAAABzaUkzlAgAABZby6SGEikMAABgXps8+biqrkrya0luTPL5JD/UWvuamfRVdSbJA7PDR1tr71jp2uYYAADAPF7oMVjrbX3uSHJfa+2mJPfNjs/nWGvtltltxaIgURgAAMCcZvsYrPW2Pu9Mcvfs/t1J3rXeC75AYQAAAPOar8dgX1Xdf87t76/hJ17XWjuYJLOv117gvF2za3+8qlZVPJhjAAAA82iZd1Wiw621Wy/0YFV9OMn153nofWv4Ga9srR2oqtck+Z2qeqC19vBLPUFhAAAAc+kyZ+Brr9ra2y/0WFU9XlX7W2sHq2p/kkMXuMaB2ddHquqjSd6UpF9hcKZVnjpVa3nKRWtpGr/GJLUTp0dH6KaWpjVar44+OzpCPzt2jE7Q1+nprKOd3btGJ+jr0t2jE/Rz7PjoBH1dednoBP0c/ppFadgsm79c6T1Jbk9y5+zrB776hKram+T51tqJqtqX5C1Jfm6lC0/rUwsAAGyWlhGTj+9McltVPZTkttlxqurWqnr/7JzXJbm/qv44yUeS3Nlae3ClCxtKBAAA89rkHoPW2pEkbzvP9+9P8p7Z/Y8lecNar60wAACAebSNmWMwisIAAADmtck7H28khQEAAMyr6TEAAIDF1mIoEQAAMK05BpYrBQAA9BgAAMDcTD4GAIAFt8hzDC7dtpw3XjmN7dCfPjWhmmjXjtEJujr9yNHREbrZccMXR0foqr3+ptERuqmliY2kPHBodIJ+nn1udIK+Dh4enaCfl18zOkFXbd/VoyN0U8dPjo6wuBa1MAAAAGZscAYAACRJUxgAAAA2OAMAgEW3yJOPAQCAcygMAABgwZl8DAAAJFEYAAAAViUCAABMPgYAAJIsbmFQSXZtW96gKJvr009PpyZa/sznR0foa9voAB3t2T06QV8nT41O0E3bd/XoCF3VZx4eHaGb9qVnRkfoqvZO532gXX/t6Ah9nT49OkE/l+4anWAxmXwMAAAkscEZAAAsupakTWMwTZJkaXQAAABgPD0GAAAwD6sSAQAASRQGAADAtOYYKAwAAGAehhIBAABJEj0GAACw4FpL02MAAAAsbI/Bs6eX8nuHL92oLJvqc89MpxVr947REbra8XVXjI7Qz+5pbVHf9u0bHYELqK+bTttM6XdJkmyfzt/g6sSJ0RH6Wp7OZ4H2sitHR1hc0+kw0GMAAABzaTGUCAAAyOIOJQIAAF5kHwMAAFh0LXoMAABg0bXoMQAAAPQYAAAASdKmsyiRwgAAAOZlKBEAACy6RR5K1JKcabVBUTbX3p1LoyN0s/z0tHaiXLpk2+gI3dSENj1JkqWDB0dH6Kbt3j06Ql+7do5O0M/JU6MT9HXgy6MT9LPn6OgEfV1/zegE/eyc0HsAw+gxAACAORlKBAAAmHwMAAALryVZnsYw+0RhAAAAc7HBGQAAkKTSJrIwT6IwAACA+TQ9BgAAQBQGAACw8FpiKBEAACy8lrQJrUo0ne1/AQBgk7W29tt6VNVVVXVvVT00+7r3Aue9sqo+VFWfraoHq+rGla69ph6D3dtabr58GlvVHz8znZpoae+u0RG4kD27Ryfo6+Q0Xv9JUoefGB2hr8v2jE7Qz6np/DtLklw5oba59urRCfo6+tzoBN3U6dOjIyysAUOJ7khyX2vtzqq6Y3b8M+c571eS/KvW2r1VdVmSFWdDTOfTMQAAbLK2XGu+rdM7k9w9u393knd99QlV9fok21tr9yZJa+3Z1trzK11YYQAAAHOYZxjReocSJbmutXbw7M9vB5Nce55zXpvkqar6H1X1qar6+arattKFTT4GAIC5zL3B2b6quv+c47taa3d95apVH05y/Xme975VXn97ku9I8qYkjyb5tSR/L8kvrfQkAABgDsvzDQ063Fq79UIPttbefqHHqurxqtrfWjtYVfuTHDrPaY8l+VRr7ZHZc34rybdmhcLAUCIAAJjHmKFE9yS5fXb/9iQfOM85n0iyt6qumR1/T5IHV7qwwgAAALaOO5PcVlUPJbltdpyqurWq3p8krbUzSX46yX1V9UCSSvKfVrqwoUQAADCHETsft9aOJHnbeb5/f5L3nHN8b5I3ruXaCgMAAJjTgH0MNozCAAAA5rSsMAAAgAXXumxYdtFYU2Hw7OnKxw5Po5a4fvfoBP3UKye2Rf1VV4xO0M3y/v2jI3S1dPDg6Aj9PPKl0Qm6aqdX3Ol+y6g3v250hL52XjI6QT8dllO5qJw+MzpBP8eeGZ1gIZ2dYzA6RT/T+JQPAAADGEoEAACYfAwAAIuuRY8BAADQ9BgAAABJprP0g8IAAADmVHoMAABg0ZljAAAAJDHHAAAASLJsgzMAAFhsbZFXJdqxlLz80o2KsrlOTWkK+bEToxNwAUtf/vLoCH0tLY1O0M+tN49O0FU99vjoCP184cDoBH3t3jk6QT+nTo1O0NfxCf0+l0/kA9oWtJzpFAYT+l8eAACYl6FEAAAwp2aOAQAALLaWslwpAAAwrTkGCgMAAJiToUQAALDg7HwMAAAkOTvPYCoUBgAAMI9m52MAAFh4hhIBAABJanGHEp1aTv7i+Y2KsrlOLo9O0E975vjoCF3V9WdGR+jn6aOjE/S1NJ03vxx9bnSCvr705OgE/VxzxegEfW3fNjpBN+2hg6MjdFX7LhsdoZ/dO0cnWFiGEgEAAIvbYwAAAJx1do7B6BT9KAwAAGBOJh8DAACZUIeBwgAAAObRmh4DAAAgyYQWuszS6AAAAMB4egwAAGBOzVAiAABYbC3TGkqkMAAAgDkt7D4Gh08/kV8+/KsblWVTvftlPzw6Qjd15e7REfo6fWZ0gn6OHx2doKv2Da8ZHaGbuuLy0RH62nfV6ATdtKv2jo7QVT377OgI3dSBI6Mj9HXJhP4+OqVPp1tK2fkYAAAWnZ2PAQCAJNFjAAAA6DEAAICFd3bn49Ep+lEYAADAnAwlAgAA9BgAAMCis8EZAACQJGnNUCIAAFhoegwAAIAkCzzHYEftzvW7vmmjsmyqpen0+qR96ZnREbqqKW1R//WvGJ2gq3rs4OgI/SwtjU7Q19HnRifopqb0Bp0kJ0+NTtDPLa8dnaCvzzw8OkE/U3vdbCETqgv0GAAAwDxakuUJzTGY2J/MAACAeegxAACAOU1pKJEeAwAAmEc7O/l4rbf1qKqrqureqnpo9nXvec55a1X90Tm341X1rpWurTAAAIA5vLBc6Vpv63RHkvtaazcluW92/JdztfaR1totrbVbknxPkueTfGilCysMAABgTq2t/bZO70xy9+z+3UlW6gn4wSS/3Vp7fqULm2MAAABzqSxnrlWJ9lXV/ecc39Vau2uVz72utXYwSVprB6vq2hXOf3eSf7OaCysMAABgTnP2ABxurd16oQer6sNJrj/PQ+9byw+pqv1J3pDkg6s5X2EAAABzeGGOQffrtvb2Cz1WVY9X1f5Zb8H+JIde4lI/lOQ3W2ur2mnRHAMAAJjTZq9KlOSeJLfP7t+e5AMvce6PJPmvq73wmnoMlrItl7WXreUpF61rdk2oJto+od8lSa68bHSCfk6cHJ2gr+eOjU7Qz9EJ/S5JsmvH6AT9nD4zOkFfp06PTtDPnktHJ+jrhpWGZm8hu3eNTrCwBuxjcGeSX6+qH0/yaJK/lSRVdWuS97bW3jM7vjHJK5L87movbCgRAADMoaVLD8DafmZrR5K87Tzfvz/Je845/nySl6/l2goDAACYR5/lRy8aCgMAAJjTRkw+HkVhAAAAcxgxlGgjKQwAAGBOE6oLFAYAADAvPQYAALDgWpKWGh2jG4UBAADMaUo9BhPbGQsAAJjHmnoMdteO3Lx9/0Zl2VTX7JpOeVff8HWjI/T19LOjE/TzsitGJ+BCTpwanaCvK/eMTtDPM0dHJ+hr31WjE3Ahx46PTsAETKnHwFAiAACYQ4tViQAAgKbHAAAASNIm1GegMAAAgDnY+RgAAEhijgEAABA9BgAAQJKmMAAAgMXWkiyPDtGRwgAAAOZkKBEAACy6tsBDiZYq2bNjaaOybKovH6/REbppn/2L0RG6qhv2jo7QzzNHRyfoa9cloxP08+r9oxP0dez46AT97LtqdIK+ptQ2T0/sPe30mdEJ+jlxcnSChWQoEQAAkGSBewwAAIAX6TEAAIAF19LSJtRloDAAAIA5TWlVomnMJAYAANZFjwEAAMxpQh0GCgMAAJhHy7SGEikMAABgHk1hAAAA5OzKRFOhMAAAgDks9FCi7VW5Ztc0FjI6PaE1Z7NzYvXd7p2jE/Rz+szoBH3tvGR0gn6eemZ0gr5esX90gm7atdeMjtBVHT4yOkI/zx8fnaCv3btGJ+hn+7bRCRbWlD5STuwTJQAAbJ5lQ4kAAAA9BgAAsOBakuXRITpSGAAAwJzahLoMFAYAADAP+xgAAABnhxJNpzJQGAAAwJwmNJJIYQAAAPNoaXoMAAAAPQYAAEAWeI7B6dbyxIlprNb6bfum04i1a1r13emP/fnoCN1su+7S0RG6qldfOzpCP9u2jU7Q1+EnRyfoZ9++0Qn6evLp0Qm6aTfeMDpCV3Xg8dER+tm5c3QCJmBanygBAGCTtCTLExpLpDAAAIA5tUUdSgQAALxoGoPsz1IYAADAHGxwBgAAJGlp5hgAAAB6DAAAYMEZSgQAACRJ2oSmHysMAABgLm1SPQZLowMAAMBW9MJQorXe1qOqrqqqe6vqodnXvRc47+eq6jNV9dmq+vdVVStde009Bmda8tTJaXSXfPTx6dREf3f3tLZB3/7XXzk6Qj+v2D86QV9HnxudoJ+nnhmdoK9jZ0Yn6Ka++NjoCH2dOjU6QTf15NOjI/T1pcOjE/Rz82tGJ1hYy5s/lOiOJPe11u6sqjtmxz9z7glV9e1J3pLkjbNv/V6S70ry0Ze68HQ+HQMAwKZqabW85ts6vTPJ3bP7dyd513mDJbuSXJJkZ5IdSR5f6cLmGAAAwBzWsSrRvqq6/5zju1prd63yude11g4mSWvtYFVd+zW5Wvt/VfWRJAeTVJL/0Fr77EoXVhgAAMCc5hxKdLi1duuFHqyqDye5/jwPvW81F6+qv5LkdUlumH3r3qr6ztba/3mp5ykMAABgLm1Dlittrb39Qo9V1eNVtX/WW7A/yaHznPYDST7eWnt29pzfTvKtSV6yMDDHAAAA5tCSLNfymm/rdE+S22f3b0/ygfOc82iS76qq7VW1I2cnHq84lEhhAAAAW8edSW6rqoeS3DY7TlXdWlXvn53zG0keTvJAkj9O8settf+50oUNJQIAgDlt9nKlrbUjSd52nu/fn+Q9s/tnkvyDtV5bYQAAAHNpI/Yx2DAKAwAAmENLNmTy8SgKAwAAmEvLcqaz8/yaCoPtVdm3a9tGZdlU22p0Ai7osj2jE3Sz/PrXj47Q1dKDD46O0M/2abyXfcXR50Yn6OfkqdEJumqvumHlk7aIevTA6Ah9XXXl6AT9/MnnRidYWHoMAABgwbW0HsuPXjQUBgAAMKeFHUoEAAC8YGN2Ph5FYQAAAHNoSZabHgMAAFhwegwAAIAkzRwDAABYdHY+BgCAhWfnYwAAIElLM/kYAABY2KFEu7e3vOFlbaOybKovPLc0OkI/y9P5B5kk2b5tdIJu6ouPjo7Q14FDoxP0s2/v6AR9XXn56AT9PH10dIKu6tDh0RH6eWpabZOdO0Yn6GfvZaMTLKg2qcnHE/p0DAAAzMtQIgAAmENL0tp0Rm4oDAAAYC6WKwUAAFqsSgQAADT7GAAAwKIzxwAAAMjUlitVGAAAwJz0GAAAAAoDAABYdG2RlyttrXJiuTYqy6Z623XPj47QTbvl5tERuqpPfGZ0hG7qsUOjI/R16c7RCfq5ZMfoBH0dmNC/tRuuH52gryNPjU7AhezbOzpBP4eeGJ1gYekxAACARdeafQwAAIDYxwAAAGiGEgEAwKKzwRkAAJDEUCIAAMBQIgAAIJnWUKKl0QEAAIDx9BgAAMBcWrKocwyqWnYutY3Ksqk+/9x0dnCtg4+PjtDX5btHJ+jn+qtHJ+hr27bRCfpZmliH6dPPjU7Qz/LB0Qn6uvzS0Qn6mdp72uEnRyfoZ8+E/u/cStq0hhLpMQAAgDm0WJUIAACwKhEAAHDWmdEBulEYAADAXPQYAAAASRZ2VSIAAOAFLdFjAAAAtExjKf9EYQAAAOugxwAAAGh6DAAAYMG1SQ0lqraGKqeqjib5042Lwwbal+Tw6BDMRdttTdpt69J2W5e227q+uu1e1Vq7ZlSY1aqq/52z2dfqcGvt+3rnWa+1Fgb3t9Zu3cA8bBBtt3Vpu61Ju21d2m7r0nZbl7a7OCyNDgAAAIynMAAAANZcGNy1ISnYDNpu69J2W5N227q03dal7bYubXcRWNMcAwAAYJoMJQIAABQGAADAKguDqvq+qvrTqvpcVd2x0aFYvZXapqp2VtWvzR7//aq6cfb9G6vqWFX90ez2Hzc7Oy9aRTt+Z1X9YVWdrqofHJGRF62nvarqzDmvu3s2LzVfbRXt+E+r6sGq+nRV3VdVrxqRk7PW015edxePVbTje6vqgVlb/V5VvX5EzkW14hyDqtqW5M+S3JbksSSfSPIjrbUHNz4eL2U1bVNVP5Hkja2191bVu5P8QGvth2cFwv9qrX3T5ifnXKtsxxuTXJHkp5Pc01r7jc1PSrL+9qqqZ1trl21mZr7WKtvxrUl+v7X2fFX9wyTf3Vr74SGBF9x628vr7uKwyna8orX2zOz+O5L8xMW4EdhUrabH4M1JPtdae6S1djLJryZ558bGYpVW0zbvTHL37P5vJHlbVdUmZmRlK7Zja+3zrbVPJ1keEZC/RHtNw2ra8SOttednhx9PcsMmZ+RF2msaVtOOz5xzuCeJVXI20WoKg5cn+eI5x4/Nvsd4q2mbr5zTWjud5OkkV88ee3VVfaqqfreqvmOjw3JBXmNby3rba1dV3V9VH6+qd/WNxhqstR1/PMlvb2giXsp628vr7uKwqnasqn9UVQ8n+bkkP7VJ2UiyfRXnnO+vy6q3i8Nq2uZC5xxM8srW2pGq+uYkv1VV3/hVlTqbw2tsa1lve72ytXagql6T5Heq6oHW2sOdsrF6q27HqvqxJLcm+a4NTcRLWW97ed1dHFbVjq21X0jyC1X1t5P8syS3b3QwzlpNj8FjSV5xzvENSQ5sTBzWaDVt85Vzqmp7kiuTPNFaO9FaO5IkrbVPJnk4yWs3PDHn4zW2tayrvVprB2ZfH0ny0SRv6hmOVVtVO1bV25O8L8k7WmsnNikbX2td7eV1d9FY6/vnrybRw7OJVlMYfCLJTVX16qq6JMm7k5jRf3FYTdvckxcr7R9M8juttVZV18wmAWX2F5SbkjyySbn5y7zGtpa526uq9lbVztn9fUneksRCDmOs2I5V9aYkv5izHzIPDcjIi+ZuL6+7i8pq2vGmcw6/P8lDm5hv4a04lKi1drqqfjLJB5NsS/KfW2uf2fBkrOhCbVNVP5vk/tbaPUl+Kcl/qarPJXkiZ1+ESfKdSX62qk4nOZPkva21Jzb/t2A17VhV35LkN5PsTfI3qupftta+cWDshbXO9npdkl+squWc/cPMnVZ4G2OV758/n+SyJP9ttmbDo621dwwLvcDW2V5edxeJVbbjT856fk4leTKGEW2qFZcrBQAAps/OxwAAgMIAAABQGAAAAFEYAAAAURgAAABZ3c7HAMxU1dVJ7psdXp+zy/1+eXb8fGvt24cEA4B1slwpwJyq6l8keba19q9HZwGA9TKUCKCTqnp29vW7q+p3q+rXq+rPqurOqvrRqvqDqnqgqr5+dt41VfXfq+oTs9tbxv4GACwyhQHAxvirSf5Jkjck+TtJXttae3OS9yf5x7Nz/l2Sf9ta+5Ykf3P2GAAMYY4BwMb4RGvtYJJU1cNJPjT7/gNJ3jq7//Ykr6+qF55zRVVd3lo7uqlJASAKA4CNcuKc+8vnHC/nxffepSTf1lo7tpnBAOB8DCUCGOdDSX7yhYOqumVgFgAWnMIAYJyfSnJrVX26qh5M8t7RgQBYXJYrBQAA9BgAAAAKAwAAIAoDAAAgCgMAACAKAwAAIAoDAAAgCgMAACDJ/wewebtx1l2DVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mfccs = datasets[3,:,:]\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title = \"MFCC\"\n",
    "\n",
    "other = np.asarray([[-0.6923731, -0.6866575, -0.4907845, -0.5046053, -0.4812429, -0.4783602, -0.4718884, -0.5127567, -0.5003926, -0.4871306, -0.4811026, -0.4982233, -0.4887495],[-0.6994145, -0.6518744, -0.4658121, -0.5165183, -0.5120193, -0.5026882, -0.4732534, -0.4982809, -0.4716989, -0.4883963, -0.5046667, -0.4781285, -0.5003163],[-0.6914756, -0.7256678, -0.5116439, -0.4861388, -0.4600886, -0.4978158, -0.4782666, -0.4792494, -0.4937109, -0.4812925, -0.505043, -0.4981351, -0.4934323],[-0.7423533, -0.737304, -0.5107797, -0.4884748, -0.4310695, -0.4727522, -0.481948, -0.4942882, -0.4874448, -0.4602431, -0.4896494, -0.4883934, -0.5096158],[-0.7648003, -0.7538806, -0.5094384, -0.5009922, -0.4728285, -0.4854127, -0.5013264, -0.5021604, -0.4818664, -0.4910938, -0.474319, -0.5065753, -0.4684232],[-0.7461025, -0.6835181, -0.5200111, -0.5531805, -0.5319076, -0.499757, -0.4973618, -0.4919881, -0.4537838, -0.4859326, -0.4584763, -0.4844208, -0.474289],[-0.7257581, -0.7274759, -0.5254108, -0.4982501, -0.4937756, -0.4877979, -0.5005925, -0.4734873, -0.4503406, -0.4685181, -0.4886954, -0.4860454, -0.4822057],[-0.7510502, -0.7218316, -0.5327671, -0.5062499, -0.4898093, -0.4899499, -0.4856581, -0.4943372, -0.4705821, -0.4798272, -0.4950685, -0.4985943, -0.4918835],[-0.7634727, -0.6993608, -0.4950949, -0.5061769, -0.4762523, -0.4978312, -0.5165401, -0.4954418, -0.4912461, -0.4717831, -0.4677967, -0.4944181, -0.4847778],[-0.8060896, -0.7215099, -0.5314006, -0.4920982, -0.4798537, -0.4978192, -0.51065, -0.503841, -0.4772306, -0.4837584, -0.4674732, -0.4851959, -0.4772013],[-0.81774, -0.7465999, -0.5344263, -0.5075384, -0.4722191, -0.4870673, -0.48579, -0.4972979, -0.4729694, -0.478571, -0.4707265, -0.5124249, -0.4864654],[-0.8513062, -0.748189, -0.5128039, -0.4935275, -0.4985091, -0.4599278, -0.4676934, -0.474686, -0.4573267, -0.4694424, -0.5178152, -0.5074592, -0.4882946],[-0.7383927, -0.7460294, -0.5256585, -0.4914636, -0.4830643, -0.4814394, -0.4943508, -0.5229667, -0.5026032, -0.4918527, -0.5311405, -0.5122969, -0.4878923],[-0.708307, -0.7133347, -0.5143939, -0.4865655, -0.4689324, -0.470508, -0.4737079, -0.4990944, -0.5050047, -0.4953766, -0.500663, -0.5087962, -0.4957435],[-0.7373954, -0.7122675, -0.5055062, -0.4867535, -0.4487781, -0.4724162, -0.5226895, -0.5259567, -0.4748634, -0.4667473, -0.4698825, -0.4888203, -0.4943985],[-0.673797, -0.6833159, -0.5327029, -0.5291833, -0.472032, -0.4769642, -0.4908413, -0.479032, -0.4911154, -0.4936467, -0.4733739, -0.4853368, -0.4786851],[-0.7177875, -0.7367923, -0.5494475, -0.5302311, -0.4833711, -0.4702683, -0.4617831, -0.4802825, -0.4846612, -0.5078804, -0.4980639, -0.4745752, -0.4561058],[-0.7150345, -0.7560655, -0.5351474, -0.5193802, -0.4820318, -0.4456904, -0.4463005, -0.4872293, -0.4873827, -0.4835555, -0.4712298, -0.4735577, -0.4648583],[-0.6486339, -0.7071985, -0.5447673, -0.5568536, -0.4899283, -0.4659044, -0.4520869, -0.5113267, -0.5348949, -0.5185094, -0.4646845, -0.4654994, -0.4805563],[-0.6584264, -0.6744861, -0.5030528, -0.5607377, -0.5006081, -0.4607392, -0.4711732, -0.496645, -0.5017421, -0.5134077, -0.4870441, -0.4615899, -0.4885234],[-0.707935, -0.7120649, -0.5104138, -0.5282019, -0.4689358, -0.4722854, -0.4964333, -0.5041111, -0.4882536, -0.4700487, -0.4867193, -0.4809232, -0.5004817],[-0.6893249, -0.7140459, -0.509423, -0.5217986, -0.4710496, -0.4610164, -0.5020482, -0.5087641, -0.4972803, -0.4778817, -0.4967815, -0.5092717, -0.4874543],[-0.7002973, -0.7292436, -0.5044175, -0.4626875, -0.4484254, -0.4956028, -0.5081065, -0.5037709, -0.5089232, -0.4786159, -0.4867086, -0.4807151, -0.4887258],[-0.6362632, -0.6614246, -0.4728621, -0.50096, -0.4860313, -0.4956293, -0.4733192, -0.4746677, -0.4963431, -0.4859842, -0.4801064, -0.5019186, -0.5172328],[-0.8866938, -0.6395247, -0.4385285, -0.4839411, -0.4892424, -0.492136, -0.4431229, -0.4742717, -0.4752559, -0.5082528, -0.505951, -0.5016147, -0.4968558]], dtype=np.float32)\n",
    "\n",
    "print(other.shape)\n",
    "\n",
    "librosa.display.specshow(other, x_axis='time')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (224, 120) (224, 7)\n"
     ]
    }
   ],
   "source": [
    "num_labels = 7\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, mfcc_stored * n_samples)).astype(np.float32)\n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(datasets, labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    # Load the training, validation and test data into constants that are\n",
    "    # attached to the graph.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,shape=(num_labels * 4 * 8, mfcc_stored * n_samples))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(num_labels * 4 * 8, num_labels))\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal([mfcc_stored * n_samples, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    tf_inference_input = tf.placeholder(tf.float32,shape=(1, mfcc_stored * n_samples), name=\"input\")\n",
    "    inf_logits = tf.matmul(tf_inference_input, weights) + biases\n",
    "    inf_prediction = tf.nn.softmax(inf_logits, name=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 4.012242\n",
      "Training accuracy: 12.9%\n",
      "Loss at step 100: 1.545997\n",
      "Training accuracy: 44.2%\n",
      "Loss at step 200: 1.180751\n",
      "Training accuracy: 59.4%\n",
      "Loss at step 300: 0.951469\n",
      "Training accuracy: 82.6%\n",
      "Loss at step 400: 0.788251\n",
      "Training accuracy: 92.0%\n",
      "Loss at step 500: 0.667219\n",
      "Training accuracy: 94.2%\n",
      "Loss at step 600: 0.575230\n",
      "Training accuracy: 96.0%\n",
      "Loss at step 700: 0.503749\n",
      "Training accuracy: 96.4%\n",
      "Loss at step 800: 0.447050\n",
      "Training accuracy: 96.4%\n",
      "Loss at step 900: 0.401226\n",
      "Training accuracy: 96.9%\n",
      "Loss at step 1000: 0.363567\n",
      "Training accuracy: 96.9%\n",
      "Loss at step 1100: 0.332155\n",
      "Training accuracy: 97.8%\n",
      "Loss at step 1200: 0.305607\n",
      "Training accuracy: 98.7%\n",
      "Loss at step 1300: 0.282907\n",
      "Training accuracy: 99.1%\n",
      "Loss at step 1400: 0.263296\n",
      "Training accuracy: 99.1%\n",
      "Loss at step 1500: 0.246198\n",
      "Training accuracy: 99.1%\n",
      "Loss at step 1600: 0.231166\n",
      "Training accuracy: 99.1%\n",
      "Loss at step 1700: 0.217854\n",
      "Training accuracy: 99.1%\n",
      "Loss at step 1800: 0.205986\n",
      "Training accuracy: 99.1%\n",
      "Loss at step 1900: 0.195341\n",
      "Training accuracy: 99.1%\n",
      "Loss at step 2000: 0.185742\n",
      "Training accuracy: 99.1%\n",
      "Saved checkpoint\n"
     ]
    }
   ],
   "source": [
    "num_steps = 2001\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    feed_dict = {tf_train_dataset : train_dataset, tf_train_labels : train_labels}\n",
    "    for step in range(num_steps):\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 100 == 0):\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Training accuracy: %.1f%%' % accuracy(predictions, train_labels))\n",
    "    saver = tf.train.Saver()\n",
    "    last_checkpoint = './model.cptk'\n",
    "    saver.save(session, last_checkpoint)\n",
    "    tf.train.write_graph(session.graph_def, \"./\", 'raw_graph_def.pb', as_text=False)\n",
    "    print(\"Saved checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.cptk\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "Converted 2 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "freeze_graph.freeze_graph(input_graph = './raw_graph_def.pb',\n",
    "              input_binary = True,\n",
    "              input_checkpoint = last_checkpoint,\n",
    "              output_node_names = \"prediction\",\n",
    "              output_graph = './model.bytes' ,\n",
    "              clear_devices = True, initializer_nodes = \"\",input_saver = \"\",\n",
    "              restore_op_name = \"save/restore_all\", filename_tensor_name = \"save/Const:0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
