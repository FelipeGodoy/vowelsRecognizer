{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.constants as const\n",
    "import scipy\n",
    "import IPython.display\n",
    "from scipy.io import wavfile\n",
    "from IPython.core.display import HTML\n",
    "from __future__ import division\n",
    "from tensorflow.python.platform import gfile\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TEST = \"./dataset/test\"\n",
    "PATH_TRAINING = \"./dataset/train\"\n",
    "n_mfcc = 20\n",
    "mfcc_start = 3\n",
    "mfcc_end = 17\n",
    "mfcc_stored = mfcc_end - mfcc_start\n",
    "n_samples = 6\n",
    "\n",
    "def load_vowel(folder, size=4):\n",
    "    wav_files = os.listdir(folder)[0:size]\n",
    "    dataset = np.ndarray(shape=(len(wav_files), mfcc_stored, n_samples), dtype=np.float32)\n",
    "    num_files = 0\n",
    "    for wav_file in wav_files:\n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.5, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 100\n",
    "        num_files += 1\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets Shape: (28, 14, 6) (28,)\n"
     ]
    }
   ],
   "source": [
    "def load_datasets(folder, size):\n",
    "    vowels = os.listdir(folder)\n",
    "    label = 0\n",
    "    vowels_amount = len(vowels)\n",
    "    datasets = np.ndarray(shape=(vowels_amount * size, mfcc_stored, n_samples), dtype=np.float32)\n",
    "    labels = np.ndarray(shape=(vowels_amount * size), dtype=np.int)\n",
    "    ind_start, ind_end = 0, size\n",
    "    for vowel in vowels:\n",
    "        vowel_folder = os.path.join(folder, vowel)\n",
    "        vowel_dataset = load_vowel(vowel_folder, size)\n",
    "        datasets[ind_start:ind_end,:,:] = vowel_dataset\n",
    "        labels[ind_start:ind_end] = label\n",
    "        ind_start += size\n",
    "        ind_end += size\n",
    "        label += 1\n",
    "    print(\"Datasets Shape:\", datasets.shape, labels.shape)\n",
    "    return datasets, labels\n",
    "\n",
    "datasets, labels = load_datasets(PATH_TRAINING, 4)\n",
    "\n",
    "#Randomize dataset\n",
    "np.random.seed(133)\n",
    "permutation = np.random.permutation(labels.shape[0])\n",
    "datasets = datasets[permutation,:,:]\n",
    "labels = labels[permutation]\n",
    "\n",
    "#save dataset\n",
    "pickle_file = os.path.join(\"./\", 'vowels.pickle')\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': datasets,\n",
    "    'train_labels': labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x22a86fa8eb8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mfccs = datasets[4,:,:]\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title = \"MFCC\"\n",
    "librosa.display.specshow(mfccs, x_axis='time')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (28, 84) (28, 7)\n"
     ]
    }
   ],
   "source": [
    "num_labels = 7\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, mfcc_stored * n_samples)).astype(np.float32)\n",
    "  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(datasets, labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-1821ef3b5d31>:17: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  # Load the training, validation and test data into constants that are\n",
    "  # attached to the graph.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(num_labels * 4, mfcc_stored * n_samples), name=\"input\")\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(num_labels * 4, num_labels), name=\"label\")\n",
    "  \n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([mfcc_stored * n_samples, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  train_prediction = tf.nn.softmax(logits, name=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 2.533169\n",
      "Training accuracy: 14.3%\n",
      "Loss at step 100: 1.352413\n",
      "Training accuracy: 50.0%\n",
      "Loss at step 200: 0.893382\n",
      "Training accuracy: 71.4%\n",
      "Loss at step 300: 0.646294\n",
      "Training accuracy: 96.4%\n",
      "Loss at step 400: 0.497023\n",
      "Training accuracy: 96.4%\n",
      "Loss at step 500: 0.399033\n",
      "Training accuracy: 96.4%\n",
      "Loss at step 600: 0.330812\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 700: 0.281129\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 800: 0.243624\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 900: 0.214466\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 1000: 0.191239\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 1100: 0.172355\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 1200: 0.156733\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 1300: 0.143617\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 1400: 0.132461\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 1500: 0.122867\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 1600: 0.114535\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 1700: 0.107235\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 1800: 0.100790\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 1900: 0.095061\n",
      "Training accuracy: 100.0%\n",
      "Loss at step 2000: 0.089936\n",
      "Training accuracy: 100.0%\n",
      "Saved checkpoint\n"
     ]
    }
   ],
   "source": [
    "num_steps = 2001\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  feed_dict = {tf_train_dataset : train_dataset, tf_train_labels : train_labels}\n",
    "  for step in range(num_steps):\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 100 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Training accuracy: %.1f%%' % accuracy(predictions, train_labels))\n",
    "  saver = tf.train.Saver()\n",
    "  last_checkpoint = './model.cptk'\n",
    "  saver.save(session, last_checkpoint)\n",
    "  tf.train.write_graph(session.graph_def, \"./\", 'raw_graph_def.pb', as_text=False)\n",
    "  print(\"Saved checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.cptk\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "Converted 2 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "freeze_graph.freeze_graph(input_graph = './raw_graph_def.pb',\n",
    "              input_binary = True,\n",
    "              input_checkpoint = last_checkpoint,\n",
    "              output_node_names = \"prediction\",\n",
    "              output_graph = './model.bytes' ,\n",
    "              clear_devices = True, initializer_nodes = \"\",input_saver = \"\",\n",
    "              restore_op_name = \"save/restore_all\", filename_tensor_name = \"save/Const:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
