{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy.constants as const\n",
    "import scipy\n",
    "import IPython.display\n",
    "from scipy.io import wavfile\n",
    "from IPython.core.display import HTML\n",
    "from __future__ import division\n",
    "from tensorflow.python.platform import gfile\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TEST = \"./dataset/test\"\n",
    "PATH_TRAINING = \"./dataset/train\"\n",
    "n_mfcc = 20\n",
    "mfcc_start = 0\n",
    "mfcc_end = 20\n",
    "mfcc_stored = mfcc_end - mfcc_start\n",
    "n_samples = 6\n",
    "\n",
    "def load_vowel(folder, size=4):\n",
    "    wav_files = os.listdir(folder)[0:size]\n",
    "    dataset = np.ndarray(shape=(len(wav_files) * 8, mfcc_stored, n_samples), dtype=np.float32)\n",
    "    num_files = 0\n",
    "    for wav_file in wav_files:\n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.125, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.25, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.375, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.5, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.625, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.75, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "        \n",
    "        wave, sr = librosa.load(os.path.join(folder, wav_file), mono=True, offset=0.875, duration=0.125)\n",
    "        mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=n_mfcc)\n",
    "        dataset[num_files,:,:] = mfccs[mfcc_start:mfcc_end, :] / 200\n",
    "        num_files += 1\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('Mean:', np.mean(dataset))\n",
    "    print('Standard deviation:', np.std(dataset))\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wave_datasets(folder, size):\n",
    "    vowels = os.listdir(folder)\n",
    "    label = 0\n",
    "    vowels_amount = len(vowels)\n",
    "    datasets = np.ndarray(shape=(vowels_amount * size * 8, mfcc_stored, n_samples), dtype=np.float32)\n",
    "    labels = np.ndarray(shape=(vowels_amount * size * 8), dtype=np.int)\n",
    "    ind_start, ind_end = 0, size *8\n",
    "    for vowel in vowels:\n",
    "        vowel_folder = os.path.join(folder, vowel)\n",
    "        vowel_dataset = load_vowel(vowel_folder, size)\n",
    "        datasets[ind_start:ind_end,:,:] = vowel_dataset\n",
    "        labels[ind_start:ind_end] = label\n",
    "        ind_start += size * 8\n",
    "        ind_end += size * 8\n",
    "        label += 1\n",
    "    print(\"Datasets Shape:\", datasets.shape, labels.shape)\n",
    "    return datasets, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_dataset(file, dataset_size):\n",
    "    dataset = np.ndarray(shape=(dataset_size, 25, 13), dtype=np.float32)\n",
    "    with open(file) as f:\n",
    "        ind = 0;\n",
    "        for line in f:\n",
    "            if(ind >= dataset_size):\n",
    "                break\n",
    "            line_arr = np.asarray(eval(line), dtype=np.float32)\n",
    "            dataset[ind,:,:] = line_arr\n",
    "            ind+=1\n",
    "    return dataset\n",
    "\n",
    "def load_datasets(folder, dataset_size):\n",
    "    vowels = os.listdir(folder)\n",
    "    vowels_amount = len(vowels)\n",
    "    label = 0\n",
    "    datasets = np.ndarray(shape=(vowels_amount * dataset_size, 25, 13), dtype=np.float32)\n",
    "    labels = np.ndarray(shape=(vowels_amount * dataset_size), dtype=np.int)\n",
    "    ind_start = 0\n",
    "    ind_end = dataset_size\n",
    "    for vowel in vowels:\n",
    "        vowel_file = os.path.join(folder, vowel)\n",
    "        vowel_dataset = load_label_dataset(vowel_file, dataset_size)\n",
    "        datasets[ind_start:ind_end,:,:] = vowel_dataset\n",
    "        labels[ind_start:ind_end] = label\n",
    "        ind_start += dataset_size\n",
    "        ind_end += dataset_size\n",
    "        label += 1\n",
    "    return datasets, labels\n",
    "datasets, labels = load_datasets(PATH_TRAINING, 36)\n",
    "test_datasets, test_labels = load_datasets(PATH_TEST, 4)\n",
    "\n",
    "permutation = np.random.permutation(labels.shape[0])\n",
    "datasets = datasets[permutation,:,:]\n",
    "labels = labels[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mfccs = datasets[7,:,:]\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title = \"MFCC\"\n",
    "\n",
    "other = np.asarray([[-0.2329923, -0.3590909, -0.2369562, -0.2604672, 0.842925, 1.089494, 0.3511549, 0.1126428, 0.01449018, 0.2433557, 0.3314657, 1.060868, 0.6938599],[-0.3908163, -0.4822866, -0.415224, -0.3859359, -0.4824052, -0.4932116, -0.3946974, -0.3777816, -0.2860443, -0.3727128, -0.3740316, -0.4854029, -0.4959383],[-0.3317419, -0.3003647, -0.3366023, -0.3382937, -0.4932948, -0.5023192, -0.4116347, -0.3663481, -0.3424717, -0.3777007, -0.3983325, -0.4964407, -0.5056154],[-0.4064817, -0.3459327, -0.3906244, -0.3989318, -0.5048913, -0.5121234, -0.4361018, -0.3991171, -0.4277389, -0.4127695, -0.4332721, -0.5077406, -0.5149552],[-0.428248, -0.3603668, -0.3963854, -0.4094014, -0.5142543, -0.5200668, -0.4588054, -0.4350089, -0.4558163, -0.446616, -0.462816, -0.5160062, -0.5209382],[-0.4543934, -0.4073784, -0.447341, -0.4542996, -0.5222021, -0.5268316, -0.4835934, -0.4682081, -0.4954573, -0.4853754, -0.4893453, -0.5246474, -0.5268012]], dtype=np.float32)\n",
    "\n",
    "librosa.display.specshow(other, x_axis='time')\n",
    "plt.colorbar()\n",
    "other.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (216, 325) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "num_labels = 6\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, 25 * 13)).astype(np.float32)\n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(datasets, labels)\n",
    "test_dataset, test_labels = reformat(test_datasets, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 6\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,shape=(216, 325))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(216, num_labels))\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal([325, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(0.005).minimize(loss)\n",
    "\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    tf_inference_input = tf.placeholder(tf.float32,shape=(1, 325), name=\"input\")\n",
    "    inf_logits = tf.matmul(tf_inference_input, weights) + biases\n",
    "    inf_prediction = tf.nn.softmax(inf_logits, name=\"prediction\")\n",
    "    \n",
    "    tf_test_input = tf.placeholder(tf.float32,shape=(24, 325))\n",
    "    test_logits = tf.matmul(tf_test_input, weights) + biases\n",
    "    test_prediction = tf.nn.softmax(test_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 14.356624\n",
      "Training accuracy: 14.4%\n",
      "Test accuracy: 8.3%\n",
      "Loss at step 100: 1.454201\n",
      "Training accuracy: 43.5%\n",
      "Test accuracy: 41.7%\n",
      "Loss at step 200: 0.959681\n",
      "Training accuracy: 61.1%\n",
      "Test accuracy: 54.2%\n",
      "Loss at step 300: 0.725877\n",
      "Training accuracy: 70.8%\n",
      "Test accuracy: 62.5%\n",
      "Loss at step 400: 0.580987\n",
      "Training accuracy: 79.6%\n",
      "Test accuracy: 62.5%\n",
      "Loss at step 500: 0.484219\n",
      "Training accuracy: 85.6%\n",
      "Test accuracy: 70.8%\n",
      "Loss at step 600: 0.416679\n",
      "Training accuracy: 88.4%\n",
      "Test accuracy: 79.2%\n",
      "Loss at step 700: 0.366356\n",
      "Training accuracy: 90.7%\n",
      "Test accuracy: 83.3%\n",
      "Loss at step 800: 0.326743\n",
      "Training accuracy: 90.7%\n",
      "Test accuracy: 83.3%\n",
      "Loss at step 900: 0.294325\n",
      "Training accuracy: 92.1%\n",
      "Test accuracy: 87.5%\n",
      "Loss at step 1000: 0.267018\n",
      "Training accuracy: 94.0%\n",
      "Test accuracy: 91.7%\n",
      "Loss at step 1100: 0.243511\n",
      "Training accuracy: 94.4%\n",
      "Test accuracy: 91.7%\n",
      "Loss at step 1200: 0.222950\n",
      "Training accuracy: 94.9%\n",
      "Test accuracy: 91.7%\n",
      "Loss at step 1300: 0.204764\n",
      "Training accuracy: 95.4%\n",
      "Test accuracy: 95.8%\n",
      "Loss at step 1400: 0.188560\n",
      "Training accuracy: 95.4%\n",
      "Test accuracy: 95.8%\n",
      "Loss at step 1500: 0.174055\n",
      "Training accuracy: 95.8%\n",
      "Test accuracy: 95.8%\n",
      "Loss at step 1600: 0.161017\n",
      "Training accuracy: 96.3%\n",
      "Test accuracy: 95.8%\n",
      "Loss at step 1700: 0.149250\n",
      "Training accuracy: 97.2%\n",
      "Test accuracy: 95.8%\n",
      "Loss at step 1800: 0.138583\n",
      "Training accuracy: 97.7%\n",
      "Test accuracy: 95.8%\n",
      "Loss at step 1900: 0.128874\n",
      "Training accuracy: 98.6%\n",
      "Test accuracy: 100.0%\n",
      "Loss at step 2000: 0.120004\n",
      "Training accuracy: 99.5%\n",
      "Test accuracy: 100.0%\n",
      "Saved checkpoint\n"
     ]
    }
   ],
   "source": [
    "num_steps = 2001\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    feed_dict = {tf_train_dataset : train_dataset, tf_train_labels : train_labels}\n",
    "    for step in range(num_steps):\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 100 == 0):\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Training accuracy: %.1f%%' % accuracy(predictions, train_labels))\n",
    "            test_predictions = session.run(test_prediction, feed_dict={tf_test_input: test_dataset})\n",
    "            print('Test accuracy: %.1f%%' % accuracy(test_predictions, test_labels))\n",
    "    saver = tf.train.Saver()\n",
    "    last_checkpoint = './model.cptk'\n",
    "    saver.save(session, last_checkpoint)\n",
    "    tf.train.write_graph(session.graph_def, \"./\", 'raw_graph_def.pb', as_text=False)\n",
    "    print(\"Saved checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.cptk\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "Converted 2 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "freeze_graph.freeze_graph(input_graph = './raw_graph_def.pb',\n",
    "              input_binary = True,\n",
    "              input_checkpoint = last_checkpoint,\n",
    "              output_node_names = \"prediction\",\n",
    "              output_graph = './model.bytes' ,\n",
    "              clear_devices = True, initializer_nodes = \"\",input_saver = \"\",\n",
    "              restore_op_name = \"save/restore_all\", filename_tensor_name = \"save/Const:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
